{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "wandb: Currently logged in as: xdvisch. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/d/master/masterproef/master_thesis/masterproef/wandb/run-20221006_141125-2ih37q0c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xdvisch/DQN_messiest/runs/2ih37q0c\" target=\"_blank\">pious-rain-1</a></strong> to <a href=\"https://wandb.ai/xdvisch/DQN_messiest\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/xdvisch/DQN_messiest/runs/2ih37q0c?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f95ff48e250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"DQN_messiest\", entity=\"xdvisch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f9586126d60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1',  render_mode='rgb_array').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "\n",
    "Tensor = FloatTensor\n",
    "\n",
    "\n",
    "Transition = namedtuple(\n",
    "    'Transition',\n",
    "    ('state', 'action', 'next_state', 'reward')\n",
    ")\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259/2250486003.py:22: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(40, interpolation=Image.CUBIC),\n",
      "/home/xdvisch/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "\n",
    "\n",
    "resize = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(40, interpolation=Image.CUBIC),\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is based on the code from gym.\n",
    "screen_width = 600\n",
    "\n",
    "\n",
    "def get_cart_location():\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose(\n",
    "        (2, 0, 1))  # transpose into torch order (CHW)\n",
    "    # Strip off the top and bottom of the screen\n",
    "\n",
    "    # print(\"Screen Size:\", screen.shape)\n",
    "    # print(\"Clipped Size:\", screen[:, 160:320].shape)\n",
    "\n",
    "    screen = screen[:, 160:320]  # all channels,\n",
    "    view_width = 320\n",
    "    cart_location = get_cart_location()\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).type(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(\n",
    "    get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "    interpolation='none',\n",
    ")\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN()\n",
    "target_net = DQN()\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    policy_net.cuda()\n",
    "    target_net.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        return policy_net(\n",
    "            Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(2)]])\n",
    "\n",
    "\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.FloatTensor(episode_durations)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None]),\n",
    "                                     volatile=True)\n",
    "    state_batch = Variable(torch.cat(batch.state))\n",
    "    action_batch = Variable(torch.cat(batch.action))\n",
    "    reward_batch = Variable(torch.cat(batch.reward))\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = Variable(torch.zeros(BATCH_SIZE).type(Tensor))\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    # Undo volatility (which was used to prevent unnecessary gradients)\n",
    "    expected_state_action_values = Variable(expected_state_action_values.data)\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259/1083248004.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
      "/tmp/ipykernel_259/1329551276.py:12: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n",
      "/tmp/ipykernel_259/1329551276.py:25: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
      "/tmp/ipykernel_259/1329551276.py:32: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Perform one step of the optimization (on the target network)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m optimize_model()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m     38\u001b[0m     episode_durations\u001b[38;5;241m.\u001b[39mappend(t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [28], line 25\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Compute V(s_{t+1}) for all next states.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mzeros(BATCH_SIZE)\u001b[38;5;241m.\u001b[39mtype(Tensor))\n\u001b[0;32m---> 25\u001b[0m next_state_values[non_final_mask] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_final_next_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Compute the expected Q values\u001b[39;00m\n\u001b[1;32m     27\u001b[0m expected_state_action_values \u001b[38;5;241m=\u001b[39m (next_state_values \u001b[38;5;241m*\u001b[39m GAMMA) \u001b[38;5;241m+\u001b[39m reward_batch\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [22], line 16\u001b[0m, in \u001b[0;36mDQN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"duration\", step_metric='episode')\n",
    "\n",
    "num_episodes = 5000\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _, _ = env.step(action.item())\n",
    "\n",
    "        reward = Tensor([reward])\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            log_dict = {\n",
    "                \"episode\": i_episode + 1,\n",
    "                \n",
    "                \"duration\": t\n",
    "                }\n",
    "            wandb.log(log_dict)\n",
    "            # plot_durations()\n",
    "            break\n",
    "    # Update the target network\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
