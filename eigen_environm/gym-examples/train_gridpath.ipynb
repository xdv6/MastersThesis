{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_game\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":32,\n",
    "    \"GAMMA\" : 0.95,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.1,\n",
    "    \"EPS_DECAY\" : 10000,\n",
    "    \"lr\":0.001, \n",
    "    \"weight_decay\":1e-5,\n",
    "    # lengte van pad *8\n",
    "    \"REPLAY_BUFFER\":30*8,\n",
    "    \"EPISODES\": 200,\n",
    "    \"TARGET_UPDATE\": 10,\n",
    "    \"SAVE_FREQ\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09fe165fa45492081900d77cd1f2795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667084980290383, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/project_ghent/masterproef/eigen_environm/gym-examples/wandb/run-20230318_105206-qpqde57e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xdvisch/gridpath_new_reward_schedule/runs/qpqde57e' target=\"_blank\">easy-energy-9</a></strong> to <a href='https://wandb.ai/xdvisch/gridpath_new_reward_schedule' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xdvisch/gridpath_new_reward_schedule' target=\"_blank\">https://wandb.ai/xdvisch/gridpath_new_reward_schedule</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xdvisch/gridpath_new_reward_schedule/runs/qpqde57e' target=\"_blank\">https://wandb.ai/xdvisch/gridpath_new_reward_schedule/runs/qpqde57e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"gridpath_new_reward_schedule\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4853/4108622542.py:8: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use BICUBIC or Resampling.BICUBIC instead.\n",
      "  T.Resize(40, interpolation=Image.CUBIC),\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", render_mode=\"rgb_array\").unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    \n",
    "    # coordinaat van linkerbovenhoek rechthoek\n",
    "    x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # left handed coordinate system\n",
    "    screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "\n",
    "    # eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    eps_threshold = 0.1\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"), weight_decay=config.get(\"weight_decay\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        # state based on patch of screen (3x3 around agent)\n",
    "        state = get_screen()\n",
    "        spel_gelukt = 0\n",
    "        \n",
    "        for t in count():\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            achieved_rewards = torch.cat((achieved_rewards, reward))\n",
    "\n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "            # if agent did not reach target after 500 actions, reset environment\n",
    "            if (t + 1) % 500 == 0:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                if reward == 1:\n",
    "                    spel_gelukt = 1\n",
    "                    win_count += 1\n",
    "\n",
    "                log_dict = {\n",
    "                    \"episode\": iteration + 1,\n",
    "                    \"reached_target\": spel_gelukt\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                wandb.log({\"number_of_actions_in_episode\": t})\n",
    "                wandb.log({\"win_count\": win_count})\n",
    "                wandb.log({\"mean_reward\": torch.mean(achieved_rewards)})\n",
    "                break\n",
    "            \n",
    "\n",
    "        # Update the target network, copying all weights and biases to target DQN\n",
    "        if iteration % config.get(\"TARGET_UPDATE\") == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # save model after frequency\n",
    "        if iteration % config.get(\"SAVE_FREQ\") == 0:\n",
    "            torch.save(policy_net, './model/gridpath_new_rewards' + str(iter) + '.pkl')\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, './model/gridpath_new_rewards.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
