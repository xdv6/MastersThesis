{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_game\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":128,\n",
    "    \"GAMMA\" : 0.99,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.1,\n",
    "    # \"EPS_DECAY\" : 40000,\n",
    "    \"lr\":0.001, \n",
    "    # \"weight_decay\":1e-5,\n",
    "    # ~ number of states * 4\n",
    "    \"REPLAY_BUFFER\":10000,\n",
    "    \"EPISODES\": 400,\n",
    "    \"TARGET_UPDATE\": 50,\n",
    "    \"SAVE_FREQ\": 10,\n",
    "    \"RESET_ENV_FREQ\": 300,\n",
    "    \"DDQN\": True,\n",
    "    \"MODEL_dir_file\": \"./model/sparse\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxdvisch\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\master\\masterproef\\master_thesis\\repo\\masterproef\\eigen_environm\\gym-examples\\wandb\\run-20230424_151342-3w366vqd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xdvisch/dqn_vs_ddqn/runs/3w366vqd\" target=\"_blank\">feasible-frost-3</a></strong> to <a href=\"https://wandb.ai/xdvisch/dqn_vs_ddqn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"sparse_reward\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_13204\\1505004635.py:8: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(15, interpolation=Image.CUBIC),\n",
      "c:\\Users\\xande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", render_mode=\"rgb_array\").unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(15, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 15, 15])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "\n",
    "    # full screen\n",
    "    # screen = screen[:,:, 520:730]\n",
    "    \n",
    "    # area around agent\n",
    "    # coordinaat van linkerbovenhoek rechthoek\n",
    "    x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # left handed coordinate system\n",
    "    screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "print(example_screen.shape)\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=4, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=4, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 4, stride = 1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "\n",
    "    # eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    eps_threshold = config.get(\"EPS_END\")\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "\n",
    "    if config.get(\"DDQN\"):\n",
    "        ### Double DQN\n",
    "        argmax_action = policy_net(non_final_next_states).max(1)[1].unsqueeze(1).detach()\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, argmax_action).squeeze(1).detach()\n",
    "    else:\n",
    "        ### DQN\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "        import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards,running_sum, counter, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        # state based on patch of screen (3x3 around agent)\n",
    "        state = get_screen()\n",
    "        spel_gelukt = 0\n",
    "        \n",
    "        for t in count():\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "            \n",
    "            running_sum += reward\n",
    "            counter += 1\n",
    "            mean = running_sum / counter\n",
    "\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "            # if agent did not reach target after RESET_ENV_FREQ actions, reset environment\n",
    "            if (t + 1) % config.get(\"RESET_ENV_FREQ\") == 0:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                if reward == 1000:\n",
    "                    spel_gelukt = 1\n",
    "                    win_count += 1\n",
    "\n",
    "                log_dict = {\n",
    "                    \"episode\": iteration + 1,\n",
    "                    \"reached_target\": spel_gelukt\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                wandb.log({\"number_of_actions_in_episode\": t})\n",
    "                wandb.log({\"win_count\": win_count})\n",
    "                wandb.log({\"mean_reward\": mean})\n",
    "                break\n",
    "            \n",
    "\n",
    "        # Update the target network, copying all weights and biases to target DQN\n",
    "        if iteration % config.get(\"TARGET_UPDATE\") == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # save model after frequency\n",
    "        if iteration % config.get(\"SAVE_FREQ\") == 0:\n",
    "            torch.save(policy_net, config.get(\"MODEL_dir_file\") + str(iteration) + '.pkl')\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_13204\\2911852527.py:50: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, argmax_action).squeeze(1).detach()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "    running_sum = achieved_rewards.sum()\n",
    "    counter = achieved_rewards.numel()\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    # policy_net = torch.load('./model/gridpath_andere_afmeting_kleinere_rb.pkl')\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, running_sum, counter, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, config.get(\"MODEL_dir_file\") + 'end.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
