{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# ! pip install gym\n",
    "# ! pip install wandb\n",
    "# ! pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_game\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":128,\n",
    "    \"GAMMA\" : 0.999,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.1,\n",
    "    # \"EPS_DECAY\" : 40000,\n",
    "    \"lr\":0.0001, \n",
    "    # \"weight_decay\":1e-5,\n",
    "    # ~ number of states * 4\n",
    "    \"REPLAY_BUFFER\":10000,\n",
    "    \"EPISODES\": 100000,\n",
    "    \"TARGET_UPDATE\": 200,\n",
    "    \"SAVE_FREQ\": 10,\n",
    "    \"RESET_ENV_FREQ\": 200,\n",
    "    \"DDQN\": False,\n",
    "    \"MODEL_dir_file\": \"./model/stop_border_lagere_lr\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxdvisch\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfff83eaf9a4e2d86f15e100b3817ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.033579071362813316, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\master\\masterproef\\master_thesis\\repo\\masterproef\\eigen_environm\\gym-examples\\wandb\\run-20230501_144949-1bxsz0he</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xdvisch/test_plot_weights/runs/1bxsz0he\" target=\"_blank\">azure-star-1</a></strong> to <a href=\"https://wandb.ai/xdvisch/test_plot_weights\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"test_plot_weights\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_12220\\1505004635.py:8: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(15, interpolation=Image.CUBIC),\n",
      "c:\\Users\\xande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", render_mode=\"rgb_array\").unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(15, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 71, 15])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "\n",
    "    # full screen\n",
    "    screen = screen[:,:, 520:730]\n",
    "    \n",
    "    # area around agent\n",
    "    # coordinaat van linkerbovenhoek rechthoek\n",
    "    # x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    # y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    # x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    # x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    # y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # # left handed coordinate system\n",
    "    # screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "print(example_screen.shape)\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=4, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=4, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 4, stride = 1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "            \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w), 4, 1))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h), 4, 1))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps_done = -100000 * ln((0.1 - eps_threshold) / 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "    # steps_done = -100000 * ln((0.1 - eps_threshold) / 0.9)\n",
    "    # eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    eps_threshold = config.get(\"EPS_END\")\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "\n",
    "    if config.get(\"DDQN\"):\n",
    "        ### Double DQN\n",
    "        argmax_action = policy_net(non_final_next_states).max(1)[1].unsqueeze(1).detach()\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, argmax_action).squeeze(1).detach()\n",
    "    else:\n",
    "        ### DQN\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "    import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    log_weights_target()\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards,running_sum, counter, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        # state based on patch of screen (3x3 around agent)\n",
    "        state = get_screen()\n",
    "        spel_gelukt = 0\n",
    "        \n",
    "        for t in count():\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "            \n",
    "            running_sum += reward\n",
    "            counter += 1\n",
    "            mean = running_sum / counter\n",
    "\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "            # if agent did not reach target after RESET_ENV_FREQ actions, reset environment\n",
    "            if (t + 1) % config.get(\"RESET_ENV_FREQ\") == 0:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                if reward == 1000:\n",
    "                    spel_gelukt = 1\n",
    "                    win_count += 1\n",
    "\n",
    "                log_dict = {\n",
    "                    \"episode\": iteration + 1,\n",
    "                    \"reached_target\": spel_gelukt\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                wandb.log({\"number_of_actions_in_episode\": t})\n",
    "                wandb.log({\"win_count\": win_count})\n",
    "                wandb.log({\"mean_reward\": mean})\n",
    "                break\n",
    "            \n",
    "\n",
    "        # Update the target network, copying all weights and biases to target DQN\n",
    "        if iteration % config.get(\"TARGET_UPDATE\") == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # save model after frequency\n",
    "        # if iteration % config.get(\"SAVE_FREQ\") == 0:\n",
    "        #     torch.save(policy_net, config.get(\"MODEL_dir_file\") + str(iteration) + '.pkl')\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "    running_sum = achieved_rewards.sum()\n",
    "    counter = achieved_rewards.numel()\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    # policy_net = torch.load('./model/gridpath_andere_afmeting_kleinere_rb.pkl')\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    wandb.watch(target_net)\n",
    "    \n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, running_sum, counter, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, config.get(\"MODEL_dir_file\") + 'end.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
