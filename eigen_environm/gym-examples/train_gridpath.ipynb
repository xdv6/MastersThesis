{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_game\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":256,\n",
    "    \"GAMMA\" : 0.99,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.1,\n",
    "    \"EPS_DECAY\" : 100000,\n",
    "    \"lr\":0.0001, \n",
    "    # \"weight_decay\":1e-5,\n",
    "    # ~ number of states * 4\n",
    "    \"REPLAY_BUFFER\":10000,\n",
    "    \"EPISODES\": 10000,\n",
    "    \"TARGET_UPDATE\": 50,\n",
    "    \"SAVE_FREQ\": 10,\n",
    "    \"RESET_ENV_FREQ\": 300,\n",
    "    \"DDQN\": True,\n",
    "    \"MODEL_dir_file\": \"model/less_layers_\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nthgnc9c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c803b33bbf5c476e83b5c1dfc9876052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>episode</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_threshold</td><td>███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss</td><td>█▇▇▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_reward</td><td>▁█</td></tr><tr><td>number_of_actions_in_episode</td><td>▁▁</td></tr><tr><td>reached_target</td><td>▁▁</td></tr><tr><td>win_count</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>episode</td><td>1</td></tr><tr><td>eps_threshold</td><td>0.99138</td></tr><tr><td>loss</td><td>0.02214</td></tr><tr><td>mean_reward</td><td>0.02333</td></tr><tr><td>number_of_actions_in_episode</td><td>299</td></tr><tr><td>reached_target</td><td>0</td></tr><tr><td>win_count</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polar-bee-1</strong>: <a href=\"https://wandb.ai/xdvisch/sparse/runs/nthgnc9c\" target=\"_blank\">https://wandb.ai/xdvisch/sparse/runs/nthgnc9c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230423_190309-nthgnc9c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nthgnc9c). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5ca7c9ae3d42a9916f10f6b6e38a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03355207443237305, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\master\\masterproef\\master_thesis\\repo\\masterproef\\eigen_environm\\gym-examples\\wandb\\run-20230423_194504-3imhaa2r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xdvisch/sparse/runs/3imhaa2r\" target=\"_blank\">balmy-frost-2</a></strong> to <a href=\"https://wandb.ai/xdvisch/sparse\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"sparse\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_17520\\730063936.py:8: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(30, interpolation=Image.CUBIC),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", render_mode=\"rgb_array\").unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(30, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 30, 30])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "\n",
    "    # full screen\n",
    "    # screen = screen[:,:, 520:730]\n",
    "    \n",
    "    # area around agent\n",
    "    # coordinaat van linkerbovenhoek rechthoek\n",
    "    x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # left handed coordinate system\n",
    "    screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "print(example_screen.shape)\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=2, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w, 4, 2), 4, 2), 2, 1)\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h, 4, 2), 4, 2), 2, 1)\n",
    "        linear_input_size = convw * convh * 64\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "\n",
    "    eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    # eps_threshold = config.get(\"EPS_END\")\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "\n",
    "    if config.get(\"DDQN\"):\n",
    "        ### Double DQN\n",
    "        argmax_action = policy_net(non_final_next_states).max(1)[1].unsqueeze(1).detach()\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, argmax_action).squeeze(1).detach()\n",
    "    else:\n",
    "        ### DQN\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "        import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards,running_sum, counter, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        # state based on patch of screen (3x3 around agent)\n",
    "        state = get_screen()\n",
    "        spel_gelukt = 0\n",
    "        \n",
    "        for t in count():\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "            \n",
    "            running_sum += reward\n",
    "            counter += 1\n",
    "            mean = running_sum / counter\n",
    "\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "            # if agent did not reach target after RESET_ENV_FREQ actions, reset environment\n",
    "            if (t + 1) % config.get(\"RESET_ENV_FREQ\") == 0:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                if reward == 1000:\n",
    "                    spel_gelukt = 1\n",
    "                    win_count += 1\n",
    "\n",
    "                log_dict = {\n",
    "                    \"episode\": iteration + 1,\n",
    "                    \"reached_target\": spel_gelukt\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                wandb.log({\"number_of_actions_in_episode\": t})\n",
    "                wandb.log({\"win_count\": win_count})\n",
    "                wandb.log({\"mean_reward\": mean})\n",
    "                break\n",
    "            \n",
    "\n",
    "        # Update the target network, copying all weights and biases to target DQN\n",
    "        if iteration % config.get(\"TARGET_UPDATE\") == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # save model after frequency\n",
    "        if iteration % config.get(\"SAVE_FREQ\") == 0:\n",
    "            torch.save(policy_net, config.get(\"MODEL_dir_file\") + str(iteration) + '.pkl')\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_17520\\2911852527.py:50: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, argmax_action).squeeze(1).detach()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "    running_sum = achieved_rewards.sum()\n",
    "    counter = achieved_rewards.numel()\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    # policy_net = torch.load('./model/gridpath_andere_afmeting_kleinere_rb.pkl')\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, running_sum, counter, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, config.get(\"MODEL_dir_file\") + 'end.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
