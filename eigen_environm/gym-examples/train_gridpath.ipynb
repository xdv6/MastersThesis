{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_game\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":128,\n",
    "    \"GAMMA\" : 0.95,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.05,\n",
    "    \"EPS_DECAY\" : 50000,\n",
    "    \"lr\":0.0001, \n",
    "    # \"weight_decay\":1e-5,\n",
    "    # ~ number of states * 4\n",
    "    \"REPLAY_BUFFER\":10000,\n",
    "    \"EPISODES\": 4000,\n",
    "    \"TARGET_UPDATE\": 4000,\n",
    "    \"SAVE_FREQ\": 10,\n",
    "    \"RESET_ENV_FREQ\": 300,\n",
    "    \"DDQN\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"y-reward\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_5308\\1256961729.py:8: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(10, interpolation=Image.CUBIC),\n",
      "c:\\Users\\xande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", render_mode=\"rgb_array\").unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(10, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "\n",
    "    # full screen\n",
    "    # screen = screen[:,:, 520:730]\n",
    "    \n",
    "    # area around agent\n",
    "    # coordinaat van linkerbovenhoek rechthoek\n",
    "    x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # left handed coordinate system\n",
    "    screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 3, stride = 1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "\n",
    "    eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    # eps_threshold = config.get(\"EPS_END\")\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "\n",
    "    if config.get(\"DDQN\"):\n",
    "        ### Double DQN\n",
    "        argmax_action = target_net(non_final_next_states).max(1)[1].unsqueeze(1).detach()\n",
    "        next_state_values[non_final_mask] = policy_net(non_final_next_states).gather(1, argmax_action).squeeze(1)\n",
    "    else:\n",
    "        ### DQN\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "        import ipdb; ipdb.set_trace()\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards,running_sum, counter, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        # state based on patch of screen (3x3 around agent)\n",
    "        state = get_screen()\n",
    "        spel_gelukt = 0\n",
    "        \n",
    "        for t in count():\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "            \n",
    "            running_sum += reward\n",
    "            counter += 1\n",
    "            mean = running_sum / counter\n",
    "\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "            # if agent did not reach target after RESET_ENV_FREQ actions, reset environment\n",
    "            if (t + 1) % config.get(\"RESET_ENV_FREQ\") == 0:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                if reward == 1000:\n",
    "                    spel_gelukt = 1\n",
    "                    win_count += 1\n",
    "\n",
    "                log_dict = {\n",
    "                    \"episode\": iteration + 1,\n",
    "                    \"reached_target\": spel_gelukt\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                wandb.log({\"number_of_actions_in_episode\": t})\n",
    "                wandb.log({\"win_count\": win_count})\n",
    "                wandb.log({\"mean_reward\": mean})\n",
    "                break\n",
    "            \n",
    "\n",
    "        # Update the target network, copying all weights and biases to target DQN\n",
    "        if iteration % config.get(\"TARGET_UPDATE\") == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # save model after frequency\n",
    "        if iteration % config.get(\"SAVE_FREQ\") == 0:\n",
    "            torch.save(policy_net, './model/ddqn_test_' + str(iteration) + '.pkl')\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "    running_sum = achieved_rewards.sum()\n",
    "    counter = achieved_rewards.numel()\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    # policy_net = torch.load('./model/gridpath_andere_afmeting_kleinere_rb.pkl')\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, running_sum, counter, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, './model/ddqn_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
