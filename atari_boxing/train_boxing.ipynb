{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":32,\n",
    "    \"GAMMA\" : 0.99,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.1,\n",
    "    \"EPS_DECAY\" : 200,\n",
    "    \"lr\":0.0001, \n",
    "    \"REPLAY_BUFFER\":10000,\n",
    "    \"EPISODES\": 10000000,\n",
    "    \"TARGET_UPDATE\": 5000,\n",
    "    \"SAVE_FREQ\": 10000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxdvisch\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d98e51ce79485f81ddf228cdab9252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03342899481455485, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\master\\masterproef\\master_thesis\\repo\\masterproef\\atari_boxing\\wandb\\run-20230417_163520-2iwnwqij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xdvisch/boxing/runs/2iwnwqij\" target=\"_blank\">wise-mountain-1</a></strong> to <a href=\"https://wandb.ai/xdvisch/boxing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"boxing\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_1212\\2393990397.py:9: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(40, interpolation=Image.CUBIC),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"Boxing-v4\", render_mode=\"rgb_array\", full_action_space=False).unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([ T.ToPILImage(),\n",
    "                    T.Grayscale(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor(),\n",
    "                    ])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    \n",
    "    # # coordinaat van linkerbovenhoek rechthoek\n",
    "    # x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    # y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    # x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    # x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    # y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # left handed coordinate system\n",
    "    # screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    screen = screen[:,30:180, 20:140]\n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none', cmap='gray')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "\n",
    "    # eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    eps_threshold = config.get(\"EPS_END\")\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards,running_sum, counter, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "\n",
    "    step = 0\n",
    "    while step < n_iters:\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        state = get_screen()\n",
    "        \n",
    "        for t in count():\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "\n",
    "            running_sum += reward\n",
    "            counter += 1\n",
    "            mean = running_sum / counter\n",
    "\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "\n",
    "            # Update the target network, copying all weights and biases to target DQN\n",
    "            if step % config.get(\"TARGET_UPDATE\") == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "            \n",
    "            # save model after frequency\n",
    "            if step % config.get(\"SAVE_FREQ\") == 0:\n",
    "                torch.save(policy_net, './model/boxing_' + str(step) + '.pkl')\n",
    "\n",
    "            if done:\n",
    "                log_dict = {\n",
    "                    \"episode\": t,\n",
    "                    \"mean_reward\": mean\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                break\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "    running_sum = achieved_rewards.sum()\n",
    "    counter = achieved_rewards.numel()\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    # policy_net = torch.load('./model/gridpath_andere_afmeting_kleinere_rb.pkl')\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, running_sum, counter, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, './model/boxing.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
